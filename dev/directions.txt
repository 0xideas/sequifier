Inference scope:
 - Add "infinite" autoregressive inference via output_to_folder (configurable number of rows per file)
 - implement kv_cache
Add encoder module with more data types and architectures, for e.g. images
Add "folding"/patching functionality to preprocessing
Add different configurable decoder modules, e.g. mlp (current), transformer, diffusion
Add hyperparameter optimization instead of just hyperparameter sampling
Enable "static" input variables to condition the sequence
Other LLM roadmap:
 - enable tokenization in preprocess and infer with pretrained tokenizer
 - enable temperature/min_p sampling
 - implement tied encoder and decoder weights
 - enable loss masking
 - enable validation set scoring within epochs
